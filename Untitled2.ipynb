{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba91d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "# Load the training data\n",
    "with open('OliveOil_TRAIN.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_train = pd.DataFrame(data)\n",
    "X_train = df_train.iloc[:,:-1].values\n",
    "y_train = df_train.iloc[:,-1].values\n",
    "\n",
    "# Load the test data\n",
    "with open('OliveOil_TEST.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_test = pd.DataFrame(data)\n",
    "X_test = df_test.iloc[:,:-1].values\n",
    "y_test = df_test.iloc[:,-1].values\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Train the model\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "prec = precision_score(y_train, y_pred, average='macro')\n",
    "recall = recall_score(y_train, y_pred, average='macro')\n",
    "f1 = f1_score(y_train, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"tab20\",  annot_kws=True, linewidths=2, linecolor=’white’, cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Train - classification report :\", clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dee271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "# Load the training data\n",
    "with open('OliveOil_TRAIN.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_train = pd.DataFrame(data)\n",
    "X_train = df_train.iloc[:,:-1].values\n",
    "y_train = df_train.iloc[:,-1].values\n",
    "\n",
    "# Load the test data\n",
    "with open('OliveOil_TEST.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_test = pd.DataFrame(data)\n",
    "X_test = df_test.iloc[:,:-1].values\n",
    "y_test = df_test.iloc[:,-1].values\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Train the model\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "prec = precision_score(y_train, y_pred, average='macro')\n",
    "recall = recall_score(y_train, y_pred, average='macro')\n",
    "f1 = f1_score(y_train, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"tab20\",  annot_kws=True, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Train - classification report :\", clr)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"tab20\",  annot_kws=True, center=0, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Train - classification report :\", clr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f05ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "# Load the training data\n",
    "with open('OliveOil_TRAIN.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_train = pd.DataFrame(data)\n",
    "X_train = df_train.iloc[:,:-1].values\n",
    "y_train = df_train.iloc[:,-1].values\n",
    "\n",
    "# Load the test data\n",
    "with open('OliveOil_TEST.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_test = pd.DataFrame(data)\n",
    "X_test = df_test.iloc[:,:-1].values\n",
    "y_test = df_test.iloc[:,-1].values\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Train the model\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "prec = precision_score(y_train, y_pred, average='macro')\n",
    "recall = recall_score(y_train, y_pred, average='macro')\n",
    "f1 = f1_score(y_train, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"tab20\",  annot_kws=True, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Train - classification report :\", clr)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"tab20\",  annot_kws=True, center=0, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Train - classification report :\", clr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "# Load the training data\n",
    "with open('OliveOil_TRAIN.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_train = pd.DataFrame(data)\n",
    "X_train = df_train.iloc[:,:-1].values\n",
    "y_train = df_train.iloc[:,-1].values\n",
    "\n",
    "# Load the test data\n",
    "with open('OliveOil_TEST.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_test = pd.DataFrame(data)\n",
    "X_test = df_test.iloc[:,:-1].values\n",
    "y_test = df_test.iloc[:,-1].values\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Train the model\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "prec = precision_score(y_train, y_pred, average='macro')\n",
    "recall = recall_score(y_train, y_pred, average='macro')\n",
    "f1 = f1_score(y_train, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"tab20\",  annot_kws=True, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Train - classification report :\", clr)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"tab20\",  annot_kws=True, center=0, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Train - classification report :\", clr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70f8bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "# Load the training data\n",
    "with open('OliveOil_TRAIN.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_train = pd.DataFrame(data)\n",
    "X_train = df_train.iloc[:,:-1].values\n",
    "y_train = df_train.iloc[:,-1].values\n",
    "\n",
    "# Load the test data\n",
    "with open('OliveOil_TEST.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_test = pd.DataFrame(data)\n",
    "X_test = df_test.iloc[:,:-1].values\n",
    "y_test = df_test.iloc[:,-1].values\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Train the model\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "prec = precision_score(y_train, y_pred, average='macro')\n",
    "recall = recall_score(y_train, y_pred, average='macro')\n",
    "f1 = f1_score(y_train, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"tab20\",  annot=True, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Train - classification report :\", clr)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"tab20\",  annot=True, center=0, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Train - classification report :\", clr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae40b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "# Load the training data\n",
    "with open('OliveOil_TRAIN.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_train = pd.DataFrame(data)\n",
    "X_train = df_train.iloc[:,:-1].values\n",
    "y_train = df_train.iloc[:,-1].values\n",
    "\n",
    "# Load the test data\n",
    "with open('OliveOil_TEST.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_test = pd.DataFrame(data)\n",
    "X_test = df_test.iloc[:,:-1].values\n",
    "y_test = df_test.iloc[:,-1].values\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Train the model\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "prec = precision_score(y_train, y_pred, average='macro')\n",
    "recall = recall_score(y_train, y_pred, average='macro')\n",
    "f1 = f1_score(y_train, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"tab20\",  annot=True, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Train - classification report :\", clr)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"tab20\",  annot=True, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Train - classification report :\", clr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcea9b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "# Load the training data\n",
    "with open('OliveOil_TRAIN.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_train = pd.DataFrame(data)\n",
    "X_train = df_train.iloc[:,:-1].values\n",
    "y_train = df_train.iloc[:,-1].values\n",
    "\n",
    "# Load the test data\n",
    "with open('OliveOil_TEST.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_test = pd.DataFrame(data)\n",
    "X_test = df_test.iloc[:,:-1].values\n",
    "y_test = df_test.iloc[:,-1].values\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Train the model\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "prec = precision_score(y_train, y_pred, average='macro')\n",
    "recall = recall_score(y_train, y_pred, average='macro')\n",
    "f1 = f1_score(y_train, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"tab20\",  annot=True,center=0, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Test report:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"tab20\",  annot=True,center=0, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e102d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "# Load the training data\n",
    "with open('OliveOil_TRAIN.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_train = pd.DataFrame(data)\n",
    "X_train = df_train.iloc[:,:-1].values\n",
    "y_train = df_train.iloc[:,-1].values\n",
    "\n",
    "# Load the test data\n",
    "with open('OliveOil_TEST.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_test = pd.DataFrame(data)\n",
    "X_test = df_test.iloc[:,:-1].values\n",
    "y_test = df_test.iloc[:,-1].values\n",
    "\n",
    "print(df_train.shape)\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Train the model\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "prec = precision_score(y_train, y_pred, average='macro')\n",
    "recall = recall_score(y_train, y_pred, average='macro')\n",
    "f1 = f1_score(y_train, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"tab20\",  annot=True,center=0, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Test report:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"tab20\",  annot=True,center=0, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2b34d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "# Load the training data\n",
    "with open('OliveOil_TRAIN.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_train = pd.DataFrame(data)\n",
    "X_train = df_train.iloc[:,:-1].values\n",
    "y_train = df_train.iloc[:,-1].values\n",
    "\n",
    "# Load the test data\n",
    "with open('OliveOil_TEST.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_test = pd.DataFrame(data)\n",
    "X_test = df_test.iloc[:,:-1].values\n",
    "y_test = df_test.iloc[:,-1].values\n",
    "\n",
    "print(df_train.shape)\n",
    "# Display all the rows\n",
    "df_test.head(30)\n",
    "\n",
    "print( df_train['target'].value_counts())\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Train the model\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "prec = precision_score(y_train, y_pred, average='macro')\n",
    "recall = recall_score(y_train, y_pred, average='macro')\n",
    "f1 = f1_score(y_train, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"tab20\",  annot=True,center=0, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Test report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"tab20\",  annot=True,center=0, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8ea59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "# Load the training data\n",
    "with open('OliveOil_TRAIN.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_train = pd.DataFrame(data)\n",
    "X_train = df_train.iloc[:,:-1].values\n",
    "y_train = df_train.iloc[:,-1].values\n",
    "\n",
    "# Load the test data\n",
    "with open('OliveOil_TEST.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_test = pd.DataFrame(data)\n",
    "X_test = df_test.iloc[:,:-1].values\n",
    "y_test = df_test.iloc[:,-1].values\n",
    "\n",
    "print(df_train.shape)\n",
    "# Display all the rows\n",
    "df_train.head(30)\n",
    "\n",
    "print( df_train['target'].value_counts())\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Train the model\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "prec = precision_score(y_train, y_pred, average='macro')\n",
    "recall = recall_score(y_train, y_pred, average='macro')\n",
    "f1 = f1_score(y_train, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"tab20\",  annot=True,center=0, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Test report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"tab20\",  annot=True,center=0, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c789ab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "# Load the training data\n",
    "with open('OliveOil_TRAIN.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_train = pd.DataFrame(data)\n",
    "X_train = df_train.iloc[:,:-1].values\n",
    "y_train = df_train.iloc[:,-1].values\n",
    "\n",
    "# Load the test data\n",
    "with open('OliveOil_TEST.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_test = pd.DataFrame(data)\n",
    "X_test = df_test.iloc[:,:-1].values\n",
    "y_test = df_test.iloc[:,-1].values\n",
    "\n",
    "print(df_train.shape)\n",
    "# Display all the rows\n",
    "df_test.head()\n",
    "df_test.describe()\n",
    "print( df_train['target'].value_counts())\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "# Train the model\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "prec = precision_score(y_train, y_pred, average='macro')\n",
    "recall = recall_score(y_train, y_pred, average='macro')\n",
    "f1 = f1_score(y_train, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"tab20\",  annot=True,center=0, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Test report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"tab20\",  annot=True,center=0, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bfedc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "# Load the training data\n",
    "with open('OliveOil_TRAIN.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_train = pd.DataFrame(data)\n",
    "X_train = df_train.iloc[:,:-1].values\n",
    "y_train = df_train.iloc[:,-1].values\n",
    "\n",
    "# Load the test data\n",
    "with open('OliveOil_TEST.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_test = pd.DataFrame(data)\n",
    "X_test = df_test.iloc[:,:-1].values\n",
    "y_test = df_test.iloc[:,-1].values\n",
    "\n",
    "print(df_train.shape)\n",
    "# Display all the rows\n",
    "df_test.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33400420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "# Load the training data\n",
    "with open('OliveOil_TRAIN.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_train = pd.DataFrame(data)\n",
    "X_train = df_train.iloc[:,:-1].values\n",
    "y_train = df_train.iloc[:,-1].values\n",
    "\n",
    "# Load the test data\n",
    "with open('OliveOil_TEST.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_test = pd.DataFrame(data)\n",
    "X_test = df_test.iloc[:,:-1].values\n",
    "y_test = df_test.iloc[:,-1].values\n",
    "\n",
    "print(df_train.shape)\n",
    "# Display all the rows\n",
    "df_test.head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803c244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "# Load the training data\n",
    "with open('OliveOil_TRAIN.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_train = pd.DataFrame(data)\n",
    "X_train = df_train.iloc[:,:-1].values\n",
    "y_train = df_train.iloc[:,-1].values\n",
    "\n",
    "# Load the test data\n",
    "with open('OliveOil_TEST.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_test = pd.DataFrame(data)\n",
    "X_test = df_test.iloc[:,:-1].values\n",
    "y_test = df_test.iloc[:,-1].values\n",
    "\n",
    "# If we want to merge all the data (train and test), so we could choose the testing data pourcentage (exp=25%):\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "X= df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "print(df_train.shape)\n",
    "\n",
    "# Display all the rows\n",
    "df_test.head(30)\n",
    "df_test.describe()\n",
    "print( df_train['target'].value_counts())\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "#--------------------------------- Naïve Bayesian Classifier------------------------------------------\n",
    "# Train the model\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "prec = precision_score(y_train, y_pred, average='macro')\n",
    "recall = recall_score(y_train, y_pred, average='macro')\n",
    "f1 = f1_score(y_train, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"plasma\",  annot=True,center=0, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Test report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"plasma\",  annot=True,center=0, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "\n",
    "#---------------------------------K-Nearest Neighbors (KNN)-----------------------------------\n",
    "# Create a KNN classifier with k=3\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Use the classifier to predict the target values for the test data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Print the predicted values\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413f65ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "# Load the training data\n",
    "with open('OliveOil_TRAIN.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_train = pd.DataFrame(data)\n",
    "X_train = df_train.iloc[:,:-1].values\n",
    "y_train = df_train.iloc[:,-1].values\n",
    "\n",
    "# Load the test data\n",
    "with open('OliveOil_TEST.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_test = pd.DataFrame(data)\n",
    "X_test = df_test.iloc[:,:-1].values\n",
    "y_test = df_test.iloc[:,-1].values\n",
    "\n",
    "print(df_train.shape)\n",
    "\n",
    "# Display all the rows\n",
    "df_test.head(30)\n",
    "df_test.describe()\n",
    "print( df_train['target'].value_counts())\n",
    "\n",
    "# If we want to merge all the data (train and test), so we could choose the testing data pourcentage (exp=25%):\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "X= df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "#--------------------------------- Naïve Bayesian Classifier------------------------------------------\n",
    "# Train the model\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "prec = precision_score(y_train, y_pred, average='macro')\n",
    "recall = recall_score(y_train, y_pred, average='macro')\n",
    "f1 = f1_score(y_train, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"plasma\",  annot=True,center=0, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Test report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"plasma\",  annot=True,center=0, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "\n",
    "#---------------------------------K-Nearest Neighbors (KNN)-----------------------------------\n",
    "# Create a KNN classifier with k=3\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Use the classifier to predict the target values for the test data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Print the predicted values\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43bcbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "# Load the training data\n",
    "with open('OliveOil_TRAIN.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_train = pd.DataFrame(data)\n",
    "X_train = df_train.iloc[:,:-1].values\n",
    "y_train = df_train.iloc[:,-1].values\n",
    "\n",
    "# Load the test data\n",
    "with open('OliveOil_TEST.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_test = pd.DataFrame(data)\n",
    "X_test = df_test.iloc[:,:-1].values\n",
    "y_test = df_test.iloc[:,-1].values\n",
    "\n",
    "print(df_train.shape)\n",
    "\n",
    "# Display all the rows\n",
    "df_test.head(30)\n",
    "df_test.describe()\n",
    "print( df_train['target'].value_counts())\n",
    "\n",
    "# If we want to merge all the data (train and test), so we could choose the testing data pourcentage (exp=25%):\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "X= df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values\n",
    "X = X.transpose()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "#--------------------------------- Naïve Bayesian Classifier------------------------------------------\n",
    "# Train the model\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "prec = precision_score(y_train, y_pred, average='macro')\n",
    "recall = recall_score(y_train, y_pred, average='macro')\n",
    "f1 = f1_score(y_train, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"plasma\",  annot=True,center=0, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Test report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"plasma\",  annot=True,center=0, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "\n",
    "#---------------------------------K-Nearest Neighbors (KNN)-----------------------------------\n",
    "# Create a KNN classifier with k=3\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Use the classifier to predict the target values for the test data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Print the predicted values\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2edae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "\n",
    "# Load the training data\n",
    "with open('OliveOil_TRAIN.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_train = pd.DataFrame(data)\n",
    "#X_train = df_train.iloc[:,:-1].values\n",
    "#y_train = df_train.iloc[:,-1].values\n",
    "\n",
    "# Load the test data\n",
    "with open('OliveOil_TEST.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_test = pd.DataFrame(data)\n",
    "#X_test = df_test.iloc[:,:-1].values\n",
    "#y_test = df_test.iloc[:,-1].values\n",
    "\n",
    "print(df_train.shape)\n",
    "\n",
    "# Display all the rows\n",
    "df_test.head(30)\n",
    "df_test.describe()\n",
    "print( df_train['target'].value_counts())\n",
    "\n",
    "# If we want to merge all the data (train and test), so we could choose the testing data pourcentage (exp=25%):\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "X= df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "#--------------------------------- Naïve Bayesian Classifier------------------------------------------\n",
    "# Train the model\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "prec = precision_score(y_train, y_pred, average='macro')\n",
    "recall = recall_score(y_train, y_pred, average='macro')\n",
    "f1 = f1_score(y_train, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"plasma\",  annot=True,center=0, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Test report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"plasma\",  annot=True,center=0, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "\n",
    "#---------------------------------K-Nearest Neighbors (KNN)-----------------------------------\n",
    "# Create a KNN classifier with k=3\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Use the classifier to predict the target values for the test data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Print the predicted values\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a661ee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Load the training data\n",
    "with open('OliveOil_TRAIN.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_train = pd.DataFrame(data)\n",
    "X_train = df_train.iloc[:,:-1].values\n",
    "y_train = df_train.iloc[:,-1].values\n",
    "\n",
    "# Load the test data\n",
    "with open('OliveOil_TEST.arff') as f:\n",
    "    data, meta = arff.loadarff(f)\n",
    "df_test = pd.DataFrame(data)\n",
    "X_test = df_test.iloc[:,:-1].values\n",
    "y_test = df_test.iloc[:,-1].values\n",
    "\n",
    "print(df_train.shape)\n",
    "\n",
    "# Display all the rows of training data\n",
    "df_train.head(30)\n",
    "df_train.describe()\n",
    "print( df_train['target'].value_counts())\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "#--------------------------------- Naïve Bayesian Classifier------------------------------------------\n",
    "# Train the model\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "prec = precision_score(y_train, y_pred, average='macro')\n",
    "recall = recall_score(y_train, y_pred, average='macro')\n",
    "f1 = f1_score(y_train, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "print(\"Naïve Bayesian Classifier:\")\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"plasma\",  annot=True, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Test report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"plasma\",  annot=True, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "\n",
    "#---------------------------------K-Nearest Neighbors (KNN)-----------------------------------\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Create a KNN classifier with k=3\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Use the classifier to predict the target values for the test data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "prec = precision_score(y_train, y_pred, average='macro')\n",
    "recall = recall_score(y_train, y_pred, average='macro')\n",
    "f1 = f1_score(y_train, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_train, y_pred)\n",
    "\n",
    "print(\"K-Nearest Neighbors Classifier:\")\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"plasma\",  annot=True, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Test report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"plasma\",  annot=True, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "\n",
    "#------------------------------Linear Discriminate Analysis (LDA)---------------------------------\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Create the LDA model\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Train the model on the training data\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = lda.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Linear Discriminate Analysis Classifier:\")\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"plasma\",  annot=True, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Test report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"plasma\",  annot=True, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "\n",
    "#------------------------------------Decision Tree-----------------------------------------\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train = sc.transform(X_train)\n",
    "sc.fit(X_test)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "\n",
    "# fit the model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "print(\"K-Nearest Neighbors Classifier:\")\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"plasma\",  annot=True, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Test report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"plasma\",  annot=True, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "\n",
    "#------------------------------Linear Discriminate Analysis (LDA)---------------------------------\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Create the LDA model\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Train the model on the training data\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = lda.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Linear Discriminate Analysis Classifier:\")\n",
    "print(\"Train report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"plasma\",  annot=True, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "clr= metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Test report:\")\n",
    "print(\"Accuracy:\", accuracy*100,\" %\")\n",
    "print(f\"Precision: {prec*100} % \")\n",
    "print(f\"Recall: {recall*100} %\")\n",
    "print(f\"F1-score: {f1*100} %\")\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, cmap=\"plasma\",  annot=True, linewidths=2, linecolor=\"white\", cbar=True)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()\n",
    "print (f\"Classification report :\", clr)\n",
    "from sklearn import tree\n",
    "tree.export_graphviz(dt, out_file='tree.dot')\n",
    "from io import StringIO\n",
    "import pydot\n",
    "out_data = StringIO()\n",
    "tree.export_graphviz(dt, out_file=out_data,\n",
    "feature_names=df_train.feature_names,class_names=dt.classes_.astype(int).astype(str), filled=True, rounded=True,special_characters=True,\n",
    "node_ids=1,)\n",
    "graph = pydot.graph_from_dot_data(out_data.getvalue())\n",
    "graph[0].write_pdf(\"oliveOil.pdf\") # save to pdf\n",
    "\n",
    "#---------------------------------Artificial Neural Networks (ANN)----------------------------\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d3b014d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c anaconda pydot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b36e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9f464c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492e6542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1858bce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ef09bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18b952d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
